# inception-of-Things
This project aims to introduce you to Kubernetes from a developer's perspective. You will have to set up small clusters and discover the mechanics of continuous integration. At the end of this project, will be able to set up a working cluster in Docker and have a usable continuous integration pipeline for applications.


# Before start

## What is Kubernetes? (K8s)
- a powerful system for managing multiple containers across many computers. It's like an operating system for a cluster of computers. Its main jobs are:
    
    - Automation (Orchestration): It automates deploying, scaling, and managing your applications. If an application crashes, Kubernetes automatically restarts it. If traffic increases, it can automatically add more containers.

    - Resource Management: It treats a group of computers (a cluster) as one giant resource pool of CPU and memory, and it intelligently decides where to run your applications.

#### How to control Kubernetes? — kubectl
- `kubectl` is the official command-line tool (CLI) for communicating with a Kubernetes cluster. Think of it as the universal remote control for your cluster.

- It allows you to tell the cluster what to do—from deploying applications to checking their status. You send commands to the cluster's "brain" (the Master Node's API Server), and it carries out the work.


**Common `kubectl` commands**
- `kubectl get`: To view resources. For example, `kubectl get nodes` shows all the computers in your cluster, and kubectl get pods shows all your running applications.

- `kubectl apply`: To create or update resources from a configuration file. You will use this command extensively in Part 2 to launch your applications.

- `kubectl describe`: To get detailed information about a specific resource, which is very useful for troubleshooting.

- `kubectl logs`: To view the logs generated by an application, helping you debug issues.

- `kubectl delete`: To remove resources from the cluster.

### Core Kubernetes Objects (The Actors and Staff)
- about Part 2:

    - Deployment (The Manager):

        - Role: It is responsible for managing how many instances (Pods) of an application should be running. It also ensures that if a Pod fails, a new one is automatically created to replace it.

        - Practice: how to use the `replicas: 3` setting for `app2` to ensure that three identical instances of the application are always running.

    - Service (The Internal Guide):

        - Role: It groups a set of running Pods together and gives that group a single, stable internal IP address. It acts as an internal guide, allowing other applications within the cluster to easily find and communicate with this group.

        - Practice: Created `app-one-svc`, `app-two-svc`, and `app-three-svc` to establish stable internal communication routes for each Deployment.

    - Ingress (The Front Desk):

        - Role: It is the single gateway that connects requests from the outside world to services inside the cluster. It defines routing rules based on the incoming address (Host), essentially saying, "Requests for app1.com go to Service A, and requests for `app2.com` go to Service B."

        - Practice: This was the core of Part 2. How to route traffic to three different services based on the `Host` header of the incoming request.

## What is K3s?
- a lightweight, certified version of Kubernetes. The creators took the full, complex Kubernetes and removed non-essential parts to make it much smaller, faster, and easier to install and use, especially for smaller environments like the one in this project.

    ### A K3s Cluster:
    - A K3s Cluster is a group of computers (nodes) that are managed by the K3s program. It has two main types of nodes, just like the ones in this project:

        - Master / Control-Plane Node (jischoiS): This is the "brain" or the "manager" of the cluster. It makes all the decisions: where to run applications, how to respond to failures, and it keeps track of the state of the entire system. In this setup, this is the controller mode machine.

        - Worker / Agent Node (jischoiSW): These are the "muscles" of the cluster. They do the actual work of running the applications (containers) as instructed by the master node. In this setup, this is the agent mode machine.

## What is Vagrant?
- a tool for building and managing virtual machine environments in a single, automated workflow.

> Imagine you have a detailed blueprint for building a custom computer. This blueprint specifies everything: the exact parts to use, the operating system to install, the network configuration, and which software to set up after it first boots.

Vagrant works just like that:

- The Blueprint: The `Vagrantfile` is that blueprint. It's a single file, in code, everything needed for your virtual environment. You specified the OS, the IP addresses, and the shell scripts to install K3s.

- The Automated Builder: When you run the `vagrant up` command in terminal, Vagrant acts as an automated builder. It reads your blueprint (`Vagrantfile`) and instructs a virtualization program like VirtualBox to build the machines exactly as specified.

    
#### The Key Advantages of Vagrant
    - Reproducibility (Solving the "It works on my machine" problem)
    - Consistency (The same environment, anywhere)
    - Automation & Portability (Simplicity and Convenience)

## Vagrant, VM, & Docker: Comparison and Relationship
- While all three technologies aim to solve the "it works on my machine" problem, they do so at different levels and scales. The relationship is best understood with a house-building analogy.

    **1. The Role of Each Technology**
    
    - **Virtual Machine (VM) - "The Land and Building Materials"**
    A VM (like VirtualBox) is the most fundamental unit of virtualization. It provides the raw materials to build a computer: virtual land (disk space), virtual utilities (CPU, memory), and a foundation upon which an operating system can be installed. By itself, it's just an empty plot with materials waiting to be used.

    - **Vagrant - "The Blueprint and Construction Company"**
    >Vagrant is the tool that directs how to build a house with those materials.

        - The Blueprint (Vagrantfile): This file specifies, "On this plot of land (the VM), build a house with a Debian 11 OS, give it the IP address 192.168.56.110, and furnish it with K3s."

        - The Construction Company (vagrant command): When you run vagrant up, Vagrant reads the blueprint and instructs VirtualBox to automatically build the house (the VM) exactly as specified.

    - **Docker - "The Prefabricated Container House"**
    >Docker takes a different approach. Instead of building from scratch, it delivers a complete, prefabricated house built in a factory.

        - Self-Contained: This container house already includes all the necessary furniture and appliances (the application and its libraries).

        - Shared Infrastructure: However, the container house doesn't have its own land or utilities (OS kernel). It's designed to be placed in an existing community (the Host OS) and share its infrastructure. This makes it incredibly lightweight and fast to set up.

    **2. Comparison Table**

    | Feature | Virtual Machine (VM) | Vagrant | Docker (Container) |
    | :--- | :--- | :--- | :--- |
    | **Core Role** | **Hardware Virtualization** | **Environment Automation** | **OS Virtualization** |
    | **End Product** | An empty virtual computer | A fully configured virtual computer | An isolated application runtime |
    | **Isolation Level** | OS Level (Full Isolation) | (Depends on VM) | Application Level (Shared Kernel) |
    | **Size / Speed** | Large & Slow (GBs, minutes to boot) | (Depends on VM) | Small & Fast (MBs, seconds to start) |
    | **Primary Purpose** | Replicating a **system environment** | Managing dev **environments as code** | Packaging & deploying **applications** |

    **3. Relationship**

    1. Vagrant & VM: "The Director and The Engine"

        - Vagrant cannot create a VM on its own; it needs a provider like VirtualBox.

        - Vagrant directs VirtualBox on what kind of VM to build, and VirtualBox executes the actual creation. Vagrant is the manager; the VM provider is the engine.

    2. VM vs. Docker: "Alternatives or a Combination"

        - A VM virtualizes a whole computer (hardware), while Docker virtualizes just an application (software). They are different approaches to isolation.

        - However, they can be used together. For example, you might run Docker inside a VM for an extra layer of security and isolation.

    3. Vagrant & Docker: "Different Kinds of Blueprints"

        - Vagrant can also use Docker as a provider. In this case, the `Vagrantfile` blueprint would instruct Docker to run a container with a specific configuration, combining the simple workflow of Vagrant with the lightweight nature of Docker.

## In this Project
    
#### Part 1 and Part 2:
    We used Vagrant to create the computers (virtual machines) that run Kubernetes, and then installed K3s (a lightweight Kubernetes) inside them.

    - Vagrant
        - Acted as the automated builder, reading the `Vagrantfile` blueprint to construct the virtual machines.

    - K3s (Lightweight Kubernetes)
        - The actual container management software that was installed inside the computers built by Vagrant.

    VirtualBox
        - The underlying engine or hypervisor that actually ran the virtual machines as instructed by Vagrant.

    YAML files
        - The declarative blueprints that told Kubernetes what the final state should look like (e.g., which applications to run and how to network them).

    Kubernetes
    - The official name and standard concept for the container management system that K3s implements.

----
    ```bash
    vagrant delete -f
    vagrant up
    vagrant status
    vagrant ssh jischoiS

    kubectl get nodes -o wide
    ```

----

## TEST Commands

### P1

    ```bash
    vagrant delete -f
    vagrant up
    vagrant status

    vagrant plugin install vagrant-vbguest
    vagrant destroy -f
    vagrant up [machin name]
    vagrant ssh jischoiS
    ```
    ```shell
    kubectl get nodes -o wide
    kubectl get pods -n kube-system
    ```

### P2

    ```bash
    vagrant up
    vagrant ssh jischoiS
    kubectl apply -f /vagrant/confs/
    kubectl get pods
    kubectl get svc
    kubectl get ingress
    ```
**Routing Test**
    ```shell
    curl -H "Host: app1.com" http://127.0.0.1
    curl -H "Host: app2.com" http://127.0.0.1
    curl http://127.0.0.1
    ```
**debugging**

    ```bash
    kubectl delete ingress main-ingress
    kubectl apply -f /vagrant/confs/ingress.yaml
    kubectl get pods -n kube-system
    kubectl delete pod [traefik-pod-name] -n kube-system
    kubectl run debug-pod ...
    ```